# LLM Configuration for Hybrid Ollama + Claude Integration

# Enable/disable LLM features
LLM_ENABLED=true
LLM_AUTO_INFER_TYPE=true
LLM_AUTO_ANALYZE=false
LLM_AUTO_SUGGEST=false

# Ollama Configuration (Local LLM)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OLLAMA_TIMEOUT=15

# Claude API Configuration (Anthropic)
ANTHROPIC_API_KEY=sk-ant-your-api-key-here
CLAUDE_MODEL=claude-3-5-haiku-20241022
CLAUDE_TIMEOUT=60
